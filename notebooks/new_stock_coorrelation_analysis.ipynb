{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between news and stock Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necssary libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from src.correlation_analysis import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load and merge the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Open      High       Low     Close  Adj Close      Volume  \\\n",
      "0  1997-05-15  0.121875  0.125000  0.096354  0.097917   0.097917  1443120000   \n",
      "1  1997-05-16  0.098438  0.098958  0.085417  0.086458   0.086458   294000000   \n",
      "2  1997-05-19  0.088021  0.088542  0.081250  0.085417   0.085417   122136000   \n",
      "3  1997-05-20  0.086458  0.087500  0.081771  0.081771   0.081771   109344000   \n",
      "4  1997-05-21  0.081771  0.082292  0.068750  0.071354   0.071354   377064000   \n",
      "\n",
      "   Dividends  Stock Splits stock_symbol  \n",
      "0        0.0           0.0         AMZN  \n",
      "1        0.0           0.0         AMZN  \n",
      "2        0.0           0.0         AMZN  \n",
      "3        0.0           0.0         AMZN  \n",
      "4        0.0           0.0         AMZN  \n"
     ]
    }
   ],
   "source": [
    "# get data path\n",
    "folder_path = '../data/yfinance_data/'\n",
    "# Automatically merge the data and assign to stock_analyzer\n",
    "corr_analyser =CorrelationAnalyzer(folder_path=folder_path)\n",
    "# Access the merged data\n",
    "print(corr_analyser.data.head())\n",
    "# save the merged data to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentment data\n",
    "stock_data=corr_analyser.merge_csv_files(folder_path)\n",
    "news_data=pd.read_csv('../data/raw_analyst_ratings/raw_analyst_ratings.csv')\n",
    "\n",
    "# drop data\n",
    "newData = news_data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>stock_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>1443120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>0.098438</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>294000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>0.088021</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>122136000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>109344000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>377064000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45423</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>175.389999</td>\n",
       "      <td>177.949997</td>\n",
       "      <td>173.570007</td>\n",
       "      <td>174.369995</td>\n",
       "      <td>174.369995</td>\n",
       "      <td>31250700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45424</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>174.250000</td>\n",
       "      <td>175.199997</td>\n",
       "      <td>169.050003</td>\n",
       "      <td>169.160004</td>\n",
       "      <td>169.160004</td>\n",
       "      <td>28967900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45425</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>168.770004</td>\n",
       "      <td>169.839996</td>\n",
       "      <td>165.865005</td>\n",
       "      <td>168.679993</td>\n",
       "      <td>168.679993</td>\n",
       "      <td>25150100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45426</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>170.500000</td>\n",
       "      <td>172.160004</td>\n",
       "      <td>169.720001</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>171.130005</td>\n",
       "      <td>13768900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45427</th>\n",
       "      <td>2024-07-30</td>\n",
       "      <td>171.830002</td>\n",
       "      <td>172.949997</td>\n",
       "      <td>170.119995</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>171.860001</td>\n",
       "      <td>13681400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45428 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        Open        High         Low       Close   Adj Close  \\\n",
       "0      1997-05-15    0.121875    0.125000    0.096354    0.097917    0.097917   \n",
       "1      1997-05-16    0.098438    0.098958    0.085417    0.086458    0.086458   \n",
       "2      1997-05-19    0.088021    0.088542    0.081250    0.085417    0.085417   \n",
       "3      1997-05-20    0.086458    0.087500    0.081771    0.081771    0.081771   \n",
       "4      1997-05-21    0.081771    0.082292    0.068750    0.071354    0.071354   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "45423  2024-07-24  175.389999  177.949997  173.570007  174.369995  174.369995   \n",
       "45424  2024-07-25  174.250000  175.199997  169.050003  169.160004  169.160004   \n",
       "45425  2024-07-26  168.770004  169.839996  165.865005  168.679993  168.679993   \n",
       "45426  2024-07-29  170.500000  172.160004  169.720001  171.130005  171.130005   \n",
       "45427  2024-07-30  171.830002  172.949997  170.119995  171.860001  171.860001   \n",
       "\n",
       "           Volume  Dividends  Stock Splits stock_symbol  \n",
       "0      1443120000        0.0           0.0         AMZN  \n",
       "1       294000000        0.0           0.0         AMZN  \n",
       "2       122136000        0.0           0.0         AMZN  \n",
       "3       109344000        0.0           0.0         AMZN  \n",
       "4       377064000        0.0           0.0         AMZN  \n",
       "...           ...        ...           ...          ...  \n",
       "45423    31250700        0.0           0.0         GOOG  \n",
       "45424    28967900        0.0           0.0         GOOG  \n",
       "45425    25150100        0.0           0.0         GOOG  \n",
       "45426    13768900        0.0           0.0         GOOG  \n",
       "45427    13681400        0.0           0.0         GOOG  \n",
       "\n",
       "[45428 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16190091/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-05 10:30:54-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>https://www.benzinga.com/news/20/06/16170189/s...</td>\n",
       "      <td>Benzinga Insights</td>\n",
       "      <td>2020-06-03 10:45:20-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71 Biggest Movers From Friday</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16103463/7...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-26 04:30:07-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46 Stocks Moving In Friday's Mid-Day Session</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095921/4...</td>\n",
       "      <td>Lisa Levin</td>\n",
       "      <td>2020-05-22 12:45:06-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B of A Securities Maintains Neutral on Agilent...</td>\n",
       "      <td>https://www.benzinga.com/news/20/05/16095304/b...</td>\n",
       "      <td>Vick Meyer</td>\n",
       "      <td>2020-05-22 11:38:59-04:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407323</th>\n",
       "      <td>Top Narrow Based Indexes For August 29</td>\n",
       "      <td>https://www.benzinga.com/news/11/08/1888782/to...</td>\n",
       "      <td>Monica Gerson</td>\n",
       "      <td>2011-08-29 00:00:00</td>\n",
       "      <td>ZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407324</th>\n",
       "      <td>Recap: Wednesday's Top Percentage Gainers and ...</td>\n",
       "      <td>https://www.benzinga.com/news/earnings/11/06/1...</td>\n",
       "      <td>Benjamin Lee</td>\n",
       "      <td>2011-06-22 00:00:00</td>\n",
       "      <td>ZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407325</th>\n",
       "      <td>UPDATE: Oppenheimer Color on China Zenix Auto ...</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/analy...</td>\n",
       "      <td>BenzingaStaffL</td>\n",
       "      <td>2011-06-21 00:00:00</td>\n",
       "      <td>ZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407326</th>\n",
       "      <td>Oppenheimer Initiates China Zenix At Outperfor...</td>\n",
       "      <td>https://www.benzinga.com/analyst-ratings/price...</td>\n",
       "      <td>Joe Young</td>\n",
       "      <td>2011-06-21 00:00:00</td>\n",
       "      <td>ZX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407327</th>\n",
       "      <td>China Zenix Auto International Opens For Tradi...</td>\n",
       "      <td>https://www.benzinga.com/news/ipos/11/05/10789...</td>\n",
       "      <td>Allie Wickman</td>\n",
       "      <td>2011-05-12 00:00:00</td>\n",
       "      <td>ZX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1407328 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  headline  \\\n",
       "0                  Stocks That Hit 52-Week Highs On Friday   \n",
       "1               Stocks That Hit 52-Week Highs On Wednesday   \n",
       "2                            71 Biggest Movers From Friday   \n",
       "3             46 Stocks Moving In Friday's Mid-Day Session   \n",
       "4        B of A Securities Maintains Neutral on Agilent...   \n",
       "...                                                    ...   \n",
       "1407323             Top Narrow Based Indexes For August 29   \n",
       "1407324  Recap: Wednesday's Top Percentage Gainers and ...   \n",
       "1407325  UPDATE: Oppenheimer Color on China Zenix Auto ...   \n",
       "1407326  Oppenheimer Initiates China Zenix At Outperfor...   \n",
       "1407327  China Zenix Auto International Opens For Tradi...   \n",
       "\n",
       "                                                       url          publisher  \\\n",
       "0        https://www.benzinga.com/news/20/06/16190091/s...  Benzinga Insights   \n",
       "1        https://www.benzinga.com/news/20/06/16170189/s...  Benzinga Insights   \n",
       "2        https://www.benzinga.com/news/20/05/16103463/7...         Lisa Levin   \n",
       "3        https://www.benzinga.com/news/20/05/16095921/4...         Lisa Levin   \n",
       "4        https://www.benzinga.com/news/20/05/16095304/b...         Vick Meyer   \n",
       "...                                                    ...                ...   \n",
       "1407323  https://www.benzinga.com/news/11/08/1888782/to...      Monica Gerson   \n",
       "1407324  https://www.benzinga.com/news/earnings/11/06/1...       Benjamin Lee   \n",
       "1407325  https://www.benzinga.com/analyst-ratings/analy...     BenzingaStaffL   \n",
       "1407326  https://www.benzinga.com/analyst-ratings/price...          Joe Young   \n",
       "1407327  https://www.benzinga.com/news/ipos/11/05/10789...      Allie Wickman   \n",
       "\n",
       "                              date stock  \n",
       "0        2020-06-05 10:30:54-04:00     A  \n",
       "1        2020-06-03 10:45:20-04:00     A  \n",
       "2        2020-05-26 04:30:07-04:00     A  \n",
       "3        2020-05-22 12:45:06-04:00     A  \n",
       "4        2020-05-22 11:38:59-04:00     A  \n",
       "...                            ...   ...  \n",
       "1407323        2011-08-29 00:00:00    ZX  \n",
       "1407324        2011-06-22 00:00:00    ZX  \n",
       "1407325        2011-06-21 00:00:00    ZX  \n",
       "1407326        2011-06-21 00:00:00    ZX  \n",
       "1407327        2011-05-12 00:00:00    ZX  \n",
       "\n",
       "[1407328 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum date from news dataset:   2009-02-14 04:00:00+00:00\n",
      "Maximum date from news dataset:   2020-06-11 21:12:35+00:00\n",
      "Minimum date from Stock dataset:   1980-12-12 00:00:00+00:00\n",
      "Max date from Stock dataset:   2024-07-30 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'date' column to datetime format and UTC-4 timezone\n",
    "stock_data['Date'] = pd.to_datetime(stock_data['Date'], format='ISO8601', utc=True)\n",
    "newData['date']=pd.to_datetime(newData['date'], format='ISO8601', utc=True)\n",
    "print(\"Minimum date from news dataset:  \",newData.date.min())\n",
    "print(\"Maximum date from news dataset:  \",newData.date.max())\n",
    "print(\"Minimum date from Stock dataset:  \",stock_data.Date.min())\n",
    "print(\"Max date from Stock dataset:  \",stock_data.Date.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
